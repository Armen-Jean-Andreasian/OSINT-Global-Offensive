services:
  redis:
    container_name: redis-container
    build:
      context: ./redis
    command: [ "redis-server", "--requirepass", "${REDIS_PASSWORD}" ]
    healthcheck:
      test: [ "CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "PING" ]
      interval: 10s
      timeout: 5s
      retries: 2
    environment:
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    expose:
      - "${REDIS_PORT}"
    volumes:
      - redis_data:/data
    networks:
      - app_network

  django:
    container_name: djangologger-container-v1
    build:
      context: ./django_project
    networks:
      - app_network
    depends_on:
      - redis
    command: python manage.py runserver 0.0.0.0:8000  # in container
    expose:
      - "8000"  # in docker network
    environment:
      - DEBUG=${DEBUG}
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_CACHE_TTL=${REDIS_CACHE_TTL}
      - DOMAIN_FOR_FAKE_URL=${DOMAIN_FOR_FAKE_URL}
    volumes:
    - static_volume:/django_project/nginx/staticfiles


  nginx:
    container_name: nginx-container
    build:
      context: ./nginx
      args:
        DJANGO_PORT: ${DJANGO_PORT}
    volumes:
      - static_volume:/django_project/nginx/staticfiles
    ports:
      - "80:80"
    depends_on:
      - django
    networks:
      - app_network
#
#  zookeeper:
#    image: confluentinc/cp-zookeeper:latest
#    container_name: zookeeper
#    environment:
#      ZOOKEEPER_CLIENT_PORT: 2181
#    networks:
#      - app_network
#
#  kafka:
#    image: confluentinc/cp-kafka:latest
#    container_name: kafka
#    depends_on:
#      - zookeeper
#    expose:
#      - "9092"
#    environment:
#      KAFKA_BROKER_ID: 1
#      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
#      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
#      KAFKA_LOG_RETENTION_HOURS: 24
#    volumes:
#      - kafka_data:/var/lib/kafka/data
#    networks:
#      - app_network
#
#
#  logstash:
#    image: docker.elastic.co/logstash/logstash:7.17.10
#    container_name: logstash
#    depends_on:
#      - kafka
#    volumes:
#      - ./system/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
#    networks:
#      - app_network
#    environment:
#      - "LS_JAVA_OPTS=-Xms512m -Xmx512m"
#
#  elasticsearch:
#    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
#    container_name: elasticsearch
#    environment:
#      - discovery.type=single-node
#    expose:
#      - "9200"
#    networks:
#      - app_network
#
#  grafana:
#    image: grafana/grafana:latest
#    container_name: grafana
#    expose:
#      - "3000"
#    depends_on:
#      - elasticsearch
#    networks:
#      - app_network

networks:
  app_network:
    driver: bridge


volumes:
  redis_data:
  static_volume:
#  kafka_data:
